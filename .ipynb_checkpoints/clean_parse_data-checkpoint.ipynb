{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from itertools import cycle, islice\n",
    "import weightedcalcs as wc\n",
    "\n",
    "# This line lets us plot on our ipython notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This python notebook parses and summarizes PUMs data\n",
    "### Four functions:\n",
    "    \n",
    "#### 1) filtercolumns: gets relevant columns from pums data, joins with povdata\n",
    "#### 2) rentersonly: gets renter hh from df from fxn 1\n",
    "#### 3) calcPov: creates poverty summary table from df from fxn 1 or 2\n",
    "#### 4) calcBurden: creates cost burden summary table from df from fxn 1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in poverty guidelines \n",
    "pov = pd.read_table(\"proj_data/pov_guidelines.csv\", sep=',', low_memory=False)\n",
    "\n",
    "#get poverty tables for ea year\n",
    "pov15=pov.iloc[:,[0,1]]\n",
    "pov10=pov.iloc[:,[0,6]]\n",
    "pov05=pov.iloc[:,[0,11]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load pums data\n",
    "pums15 = \"proj_data/ss15hpa_1yr.csv\"\n",
    "pums10=\"proj_data/ss10hpa.csv\"\n",
    "pums05=\"proj_data/ss05hpa.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>ST</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>WGTP</th>\n",
       "      <th>NP</th>\n",
       "      <th>TEN</th>\n",
       "      <th>BLD</th>\n",
       "      <th>RNTP</th>\n",
       "      <th>VACS</th>\n",
       "      <th>HINCP</th>\n",
       "      <th>SMOCP</th>\n",
       "      <th>GRNTP</th>\n",
       "      <th>GRPIP</th>\n",
       "      <th>OCPIP</th>\n",
       "      <th>KIT</th>\n",
       "      <th>PLM</th>\n",
       "      <th>hhd_size</th>\n",
       "      <th>pov_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>2600</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>603.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172</td>\n",
       "      <td>42</td>\n",
       "      <td>3502</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>11770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>42</td>\n",
       "      <td>1900</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>208</td>\n",
       "      <td>42</td>\n",
       "      <td>2002</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>352</td>\n",
       "      <td>42</td>\n",
       "      <td>500</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21700.0</td>\n",
       "      <td>755.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11770.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIALNO  ST  PUMA  WGTP  NP  TEN  BLD   RNTP  VACS    HINCP  SMOCP  GRNTP  \\\n",
       "0        26  42  2600    37   1  3.0  2.0  500.0   NaN  45000.0    NaN  603.0   \n",
       "1       172  42  3502     0   1  NaN  NaN    NaN   NaN      NaN    NaN    NaN   \n",
       "2       206  42  1900    76   1  4.0  3.0    NaN   NaN  19000.0    NaN    NaN   \n",
       "3       208  42  2002    80   1  3.0  9.0  290.0   NaN  14900.0    NaN  360.0   \n",
       "4       352  42   500    23   1  2.0  2.0    NaN   NaN  21700.0  755.0    NaN   \n",
       "\n",
       "   GRPIP  OCPIP  KIT  PLM  hhd_size   pov_15  \n",
       "0   16.0    NaN  1.0  1.0         1  11770.0  \n",
       "1    NaN    NaN  NaN  NaN         1  11770.0  \n",
       "2    NaN    NaN  1.0  1.0         1  11770.0  \n",
       "3   29.0    NaN  1.0  1.0         1  11770.0  \n",
       "4    NaN   42.0  1.0  1.0         1  11770.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filtercolumns(pumsdata, povdata):\n",
    "    \"\"\"\n",
    "    function filtercolumns pulls relevant columns from each year's pums households data (csv)\n",
    "    and joins with poverty data based on hhd_size, \n",
    "    povdata (a DF of just that year's poverty guidelines) \n",
    "    returns df of pums data with joined pov data\n",
    "    \"\"\"\n",
    "    pums = pd.read_table(pumsdata,sep=\",\", low_memory=False)\n",
    "    df_relevant = pums[['SERIALNO','ST', 'PUMA', 'WGTP', 'NP', 'TEN', 'BLD', 'RNTP', 'VACS','HINCP','SMOCP','GRNTP', 'GRPIP','OCPIP', 'KIT', 'PLM']]\n",
    "    pums_pov = df_relevant.merge(povdata, left_on='NP', right_on='hhd_size')\n",
    "    return pums_pov\n",
    "\n",
    "# test code\n",
    "fd15=filtercolumns(pums15,pov15)\n",
    "fd15.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rentersonly(data, yyyy):\n",
    "    \"\"\"\n",
    "    pulls renter records \n",
    "    requires two arguments, \n",
    "    data is pums df with joined pov data\n",
    "    yyyy is 4-digit year, eg 2015\n",
    "    returns renters df\n",
    "    \n",
    "    \"\"\"\n",
    "    #convert yyyy to pov_yy, eg 2015 to pov_15\n",
    "    yyyys = str(yyyy)\n",
    "    yy=yyyys[-2:]\n",
    "    povyear = \"pov\" + \"_\" + yy\n",
    "    \n",
    "    #filter renters with complete kitchen and plumbing\n",
    "    r = data[data['TEN']==3]\n",
    "    rK = r[r['KIT']==1]\n",
    "    rKP = rK[rK['PLM']==1]\n",
    "    return rKP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ownersonly(data, yyyy):\n",
    "    \"\"\"\n",
    "    pulls homeowners records \n",
    "    requires two arguments, \n",
    "    data is pums df with joined pov data\n",
    "    yyyy is 4-digit year, eg 2015\n",
    "    returns owners df\n",
    "    \n",
    "    \"\"\"\n",
    "    #convert yyyy to pov_yy, eg 2015 to pov_15\n",
    "    yyyys = str(yyyy)\n",
    "    yy=yyyys[-2:]\n",
    "    povyear = \"pov\" + \"_\" + yy\n",
    "    \n",
    "    #filter homeowners with complete kitchen and plumbing\n",
    "    h = data[(data['TEN']==1) | (data['TEN']==2)] \n",
    "    hK = h[h['KIT']==1]\n",
    "    hKP = hK[hK['PLM']==1]\n",
    "    return hKP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calcPov(data, yyyy, exportname=\"\"):\n",
    "    \"\"\"\n",
    "    calculates % of HH below federal poverty line in each PUMA. \n",
    "    requires 2 arguments:\n",
    "    data is pums df with joined pov data (can be df from rentersonly or ownersonly)\n",
    "    yyyy is 4-digit year, eg 2015\n",
    "    exportname is export csv name\n",
    "    if no exportname is provided, returns pct poverty by puma as DF \n",
    "    otherwise returns csv\n",
    "    \n",
    "    \"\"\"\n",
    "    #convert yyyy to pov_yy, eg 2015 to pov_15\n",
    "    yyyys = str(yyyy)\n",
    "    yy=yyyys[-2:]\n",
    "    povyear = \"pov\" + \"_\" + str(yy)\n",
    "    \n",
    "    #add new column\n",
    "    data['WGTPpov'] = data['WGTP'].where(data['HINCP']<=data[povyear], 0)\n",
    "    \n",
    "    #group by Puma\n",
    "    grp = data.groupby([\"PUMA\"])\n",
    "    \n",
    "    #summarize hhs below poverty\n",
    "    povsum = grp[['WGTP','WGTPpov']].sum()\n",
    "    \n",
    "    #calc %\n",
    "    povsum['PCTpov'] = (povsum['WGTPpov'] / povsum['WGTP'])*100\n",
    "    \n",
    "    #determine what fxn returns\n",
    "    if len(exportname)>0:\n",
    "        povsum.to_csv(exportname)\n",
    "        print(str(yyyy)+\" poverty summary table successfully exported to csv\")\n",
    "    else:\n",
    "        return povsum\n",
    "    \n",
    "#code to test that it worked!\n",
    "# naming convention: r15_poverty\n",
    "#calcPov(rentersonly(fd15,2015),2015,\"r15_pov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RcalcBurden(data, yyyy, exportname=\"\"):\n",
    "    \"\"\"\n",
    "    calculates % of HH with cost burden greater than 30% in ea puma for RENTERS\n",
    "    requires 2 arguments:\n",
    "    data is pums df with joined pov data (can be df from rentersonly)\n",
    "    exportname is export csv name\n",
    "    if no exportname is provided, returns pct with cost burden >30% by puma as DF \n",
    "    otherwise returns csv    \n",
    "    \"\"\"\n",
    "    #convert yyyy to pov_yy, eg 2015 to pov_15\n",
    "    yyyys = str(yyyy)\n",
    "    yy=yyyys[-2:]\n",
    "    povyear = \"pov\" + \"_\" + str(yy)\n",
    "    \n",
    "    #from renters only table, grab only hh below pov line\n",
    "    need = data[(data['HINCP']<=data[povyear]) & (data['GRPIP'].notnull())]\n",
    "    \n",
    "    #add new column for 30% burden\n",
    "    need['WGTP30'] = need['WGTP'].where(need['GRPIP']>=30.0, 0)\n",
    "    \n",
    "    #add new column for 50% burden\n",
    "    need['WGTP50'] = need['WGTP'].where(need['GRPIP']>=50.0, 0)\n",
    "    \n",
    "    #group by puma\n",
    "    grp = need.groupby([\"PUMA\"])\n",
    "    \n",
    "    #calculate totals by PUMA of hhds and hhds with burden over 30% and 50%\n",
    "    burdensum = grp[['WGTP','WGTP30','WGTP50']].sum()\n",
    "    \n",
    "    #add pct column for 30%\n",
    "    burdensum['PCTburden30'] = (burdensum['WGTP30'] / burdensum['WGTP'])*100\n",
    "    \n",
    "    # add pct column for 50%\n",
    "    burdensum['PCTburden50'] = (burdensum['WGTP50'] / burdensum['WGTP'])*100\n",
    "    \n",
    "    #export or return df\n",
    "    if len(exportname)>0:\n",
    "        burdensum.to_csv(exportname)\n",
    "        print(str(yyyy)+\" burden summary table successfully exported to csv\")\n",
    "    else:\n",
    "        return burdensum\n",
    "\n",
    "\n",
    "#code to test that it worked!\n",
    "#RcalcBurden(rentersonly(fd15,15),15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def HcalcBurden(data, yyyy, exportname=\"\"):\n",
    "    \"\"\"\n",
    "    calculates % of HH with cost burden greater than 30% in ea puma for OWNERS\n",
    "    requires 2 arguments:\n",
    "    data is pums df with joined pov data (can be df from ownersonly)\n",
    "    exportname is export csv name\n",
    "    if no exportname is provided, returns pct with cost burden >30% by puma as DF \n",
    "    otherwise returns csv    \n",
    "    \"\"\"\n",
    "    #convert yyyy to pov_yy, eg 2015 to pov_15\n",
    "    yyyys = str(yyyy)\n",
    "    yy=yyyys[-2:]\n",
    "    povyear = \"pov\" + \"_\" + str(yy)\n",
    "    \n",
    "    #from renters only table, grab only hh below pov line\n",
    "    need = data[(data['HINCP']<=data[povyear]) & (data['OCPIP'].notnull())]\n",
    "    \n",
    "    #add new column for 30% burden\n",
    "    need['WGTP30'] = need['WGTP'].where(need['OCPIP']>=30.0, 0)\n",
    "    \n",
    "     #add new column for 50% burden\n",
    "    need['WGTP50'] = need['WGTP'].where(need['OCPIP']>=50.0, 0)\n",
    "    \n",
    "    #group by puma\n",
    "    grp = need.groupby([\"PUMA\"])\n",
    "    \n",
    "    #calculate totals by PUMA of hhds and hhds with burden over 30% and 50%\n",
    "    burdensum = grp[['WGTP','WGTP30','WGTP50']].sum()\n",
    "    \n",
    "    #add pct column for 30%\n",
    "    burdensum['PCTburden30'] = (burdensum['WGTP30'] / burdensum['WGTP'])*100\n",
    "    \n",
    "    # add pct column for 50%\n",
    "    burdensum['PCTburden50'] = (burdensum['WGTP50'] / burdensum['WGTP'])*100\n",
    "    \n",
    "    #export or return df\n",
    "    if len(exportname)>0:\n",
    "        burdensum.to_csv(exportname)\n",
    "        print(str(yyyy)+\" burden summary table successfully exported to csv\")\n",
    "    else:\n",
    "        return burdensum\n",
    "\n",
    "\n",
    "#code to test that it worked!\n",
    "#HcalcBurden(ownersonly(fd15,15),15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phoebe/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/phoebe/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 burden summary table successfully exported to csv\n",
      "2010 burden summary table successfully exported to csv\n",
      "2005 burden summary table successfully exported to csv\n",
      "2015 poverty summary table successfully exported to csv\n",
      "2010 poverty summary table successfully exported to csv\n",
      "2005 poverty summary table successfully exported to csv\n"
     ]
    }
   ],
   "source": [
    "## RUN FUNCTIONS TO PRODUCE RENTER CSVs FOR ALL YEARS\n",
    "RcalcBurden(rentersonly(filtercolumns(pums15, pov15),2015),2015,\"r15_burden.csv\")\n",
    "RcalcBurden(rentersonly(filtercolumns(pums10, pov10),2010),2010,\"r10_burden.csv\")\n",
    "RcalcBurden(rentersonly(filtercolumns(pums05, pov05),2005),2005,\"r05_burden.csv\")\n",
    "calcPov(rentersonly(filtercolumns(pums15, pov15),2015),2015, \"r15_poverty.csv\")\n",
    "calcPov(rentersonly(filtercolumns(pums10, pov10),2010),2010, \"r10_poverty.csv\")\n",
    "calcPov(rentersonly(filtercolumns(pums05, pov05),2005),2005, \"r05_poverty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phoebe/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/phoebe/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 burden summary table successfully exported to csv\n",
      "2010 burden summary table successfully exported to csv\n",
      "2005 burden summary table successfully exported to csv\n",
      "2015 poverty summary table successfully exported to csv\n",
      "2010 poverty summary table successfully exported to csv\n",
      "2005 poverty summary table successfully exported to csv\n"
     ]
    }
   ],
   "source": [
    "## RUN FUNCTIONS TO PRODUCE HOMEOWNER CSVs FOR ALL YEARS\n",
    "HcalcBurden(ownersonly(filtercolumns(pums15, pov15),2015),2015,\"h15_burden.csv\")\n",
    "HcalcBurden(ownersonly(filtercolumns(pums10, pov10),2010),2010,\"h10_burden.csv\")\n",
    "HcalcBurden(ownersonly(filtercolumns(pums05, pov05),2005),2005,\"h05_burden.csv\")\n",
    "calcPov(ownersonly(filtercolumns(pums15, pov15),2015),2015, \"h15_poverty.csv\")\n",
    "calcPov(ownersonly(filtercolumns(pums10, pov10),2010),2010, \"h10_poverty.csv\")\n",
    "calcPov(ownersonly(filtercolumns(pums05, pov05),2005),2005, \"h05_poverty.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n",
    "\"\"\"\n",
    "basically, use filter fxn to filter columns + join pov, then use rentersonly to grab only renter \n",
    "households. then calcBurden or calcPov to get summary tables \n",
    "NOTE: should be able to adjust calcBurden and calcPov so we can use these fxns for \n",
    "owners too\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burden summary table successfully exported to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Results: Run code here when ready to export\n",
    "\n",
    "#no export, returns dfs\n",
    "# calcBurden(rentersonly(filtercolumns(pums10, pov10),2010),2010)\n",
    "# calcBurden(rentersonly(filtercolumns(pums05, pov05),2005),2005)\n",
    "# calcPov(rentersonly(filtercolumns(pums10, pov10),2010),2010)\n",
    "# calcPov(rentersonly(filtercolumns(pums05, pov05),2005),2005)\n",
    "\n",
    "#export to csv\n",
    "# calcBurden(rentersonly(filtercolumns(pums10, pov10),2010),2010,\"r10_totalsburden30.csv\")\n",
    "# calcBurden(rentersonly(filtercolumns(pums05, pov05),2005),2005,\"r05_totalsburden30.csv\")\n",
    "# calcPov(rentersonly(filtercolumns(pums10, pov10),2010),2010, \"r10_poverty.csv\")\n",
    "# calcPov(rentersonly(filtercolumns(pums05, pov05),2005),2005, \"r05_poverty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
